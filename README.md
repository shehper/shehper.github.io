# Ali Shehper

I am a Physicist, currently researching the mechanistic interpretability of AI systems and the use of AI systems to solve Math problems. I am currently employed at Rutgers University. 

My current research interests include:

- understanding the internals of AI systems. (See my implementation of Anthropic's Sparse Dictionary Learning paper [here](https://github.com/shehper/monosemantic) and its associated [interface](https://shehper.github.io/feature-interface/) to explore features learned by a language model.)
- using classical and deep learning search techniques to solve open Math problems. My collaborators and I have solved many potential counterexamples of the [Andrews-Curtis conjecture](https://en.wikipedia.org/wiki/Andrews%E2%80%93Curtis_conjecture) recently. This work will be published soon.

  
My research is inspired by the scaling of AI models and their capabilities in the recent years. See [my implementation](https://github.com/shehper/monosemantic) of [the first scaling laws paper](https://arxiv.org/abs/2001.08361), which indicates that the optimal scaling of the size of langauge models is independent of the choice of training dataset (when keeping hyperparameters and the choice of tokenizer fixed). It is known that this scaling law depends on various hyperparameters, courtesy of the Chinchilla scaling law.

During my PhD at UT Austin, I studied theoretical aspects of quantum field theories and used them to discover new results in Math. My PhD thesis is available [here](https://repositories.lib.utexas.edu/server/api/core/bitstreams/47a5901a-8078-4145-91a4-c4463928d1d1/content), and a list of my research papers is available [here](https://scholar.google.com/citations?user=FkUMJF4AAAAJ&hl=en&oi=sra). 

Please feel free to send a message if you would like to chat.

[Google Scholar](https://scholar.google.com/citations?user=FkUMJF4AAAAJ&hl=en&oi=ao) / [GitHub](https://github.com/shehper) / [Twitter](https://twitter.com/AShehper) / [LinkedIn](https://www.linkedin.com/in/ali-shehper/)
